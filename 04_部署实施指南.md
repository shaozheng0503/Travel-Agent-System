# æ—…æ¸¸Agentéƒ¨ç½²å®æ–½æŒ‡å—

## ğŸš€ éƒ¨ç½²æ¦‚è¿°

### éƒ¨ç½²æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è´Ÿè½½å‡è¡¡å™¨     â”‚    â”‚   åº”ç”¨æœåŠ¡å™¨     â”‚    â”‚   æ•°æ®åº“æœåŠ¡å™¨   â”‚
â”‚   (Nginx)       â”‚    â”‚   (Node.js)     â”‚    â”‚   (MongoDB)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - åå‘ä»£ç†      â”‚    â”‚ - å‰ç«¯æœåŠ¡      â”‚    â”‚ - ä¸»æ•°æ®åº“      â”‚
â”‚ - SSLç»ˆæ­¢       â”‚    â”‚ - åç«¯API       â”‚    â”‚ - ç¼“å­˜æ•°æ®åº“    â”‚
â”‚ - é™æ€æ–‡ä»¶      â”‚    â”‚ - å¾®æœåŠ¡        â”‚    â”‚ - æ–‡ä»¶å­˜å‚¨      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### éƒ¨ç½²ç¯å¢ƒ
- **å¼€å‘ç¯å¢ƒ**: æœ¬åœ°å¼€å‘ã€åŠŸèƒ½æµ‹è¯•
- **æµ‹è¯•ç¯å¢ƒ**: é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
- **é¢„ç”Ÿäº§ç¯å¢ƒ**: ç”¨æˆ·éªŒæ”¶æµ‹è¯•
- **ç”Ÿäº§ç¯å¢ƒ**: æ­£å¼ä¸Šçº¿æœåŠ¡

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

#### æœåŠ¡å™¨é…ç½®
```bash
# æœ€ä½é…ç½®
CPU: 2æ ¸å¿ƒ
å†…å­˜: 4GB
å­˜å‚¨: 50GB SSD
ç½‘ç»œ: 100Mbps

# æ¨èé…ç½®
CPU: 4æ ¸å¿ƒ
å†…å­˜: 8GB
å­˜å‚¨: 100GB SSD
ç½‘ç»œ: 1Gbps

# ç”Ÿäº§ç¯å¢ƒé…ç½®
CPU: 8æ ¸å¿ƒ
å†…å­˜: 16GB
å­˜å‚¨: 200GB SSD
ç½‘ç»œ: 1Gbps
```

#### æ“ä½œç³»ç»Ÿ
```bash
# æ¨èç³»ç»Ÿ
Ubuntu 20.04 LTS
CentOS 8
Debian 11

# ç³»ç»Ÿæ›´æ–°
sudo apt update && sudo apt upgrade -y
sudo yum update -y
```

### 2. åŸºç¡€è½¯ä»¶å®‰è£…

#### Node.jså®‰è£…
```bash
# ä½¿ç”¨NodeSourceä»“åº“å®‰è£…Node.js 18.x
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# éªŒè¯å®‰è£…
node --version
npm --version

# å®‰è£…PM2è¿›ç¨‹ç®¡ç†å™¨
sudo npm install -g pm2
```

#### Dockerå®‰è£…
```bash
# å®‰è£…Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å¯åŠ¨DockeræœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# å®‰è£…Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

#### MongoDBå®‰è£…
```bash
# æ·»åŠ MongoDBå®˜æ–¹ä»“åº“
wget -qO - https://www.mongodb.org/static/pgp/server-5.0.asc | sudo apt-key add -
echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/5.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-5.0.list

# å®‰è£…MongoDB
sudo apt-get update
sudo apt-get install -y mongodb-org

# å¯åŠ¨MongoDBæœåŠ¡
sudo systemctl start mongod
sudo systemctl enable mongod

# éªŒè¯å®‰è£…
mongo --version
```

#### Rediså®‰è£…
```bash
# å®‰è£…Redis
sudo apt-get install -y redis-server

# é…ç½®Redis
sudo nano /etc/redis/redis.conf

# ä¿®æ”¹é…ç½®
bind 127.0.0.1
port 6379
maxmemory 256mb
maxmemory-policy allkeys-lru

# å¯åŠ¨RedisæœåŠ¡
sudo systemctl start redis-server
sudo systemctl enable redis-server

# éªŒè¯å®‰è£…
redis-cli ping
```

#### Nginxå®‰è£…
```bash
# å®‰è£…Nginx
sudo apt-get install -y nginx

# å¯åŠ¨NginxæœåŠ¡
sudo systemctl start nginx
sudo systemctl enable nginx

# éªŒè¯å®‰è£…
nginx -v
```

## ğŸ“¦ é¡¹ç›®éƒ¨ç½²

### 1. é¡¹ç›®ç»“æ„
```bash
travel-agent/
â”œâ”€â”€ frontend/                 # å‰ç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ backend/                  # åç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ docker/                   # Dockeré…ç½®
â”‚   â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ backend/
â”‚   â””â”€â”€ nginx/
â”œâ”€â”€ scripts/                  # éƒ¨ç½²è„šæœ¬
â”œâ”€â”€ config/                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ docker-compose.yml        # Dockerç¼–æ’
â””â”€â”€ README.md
```

### 2. ç¯å¢ƒé…ç½®

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# .env æ–‡ä»¶
NODE_ENV=production
PORT=3000

# æ•°æ®åº“é…ç½®
MONGODB_URI=mongodb://localhost:27017/travel_agent
REDIS_URL=redis://localhost:6379

# APIå¯†é’¥
AMAP_KEY=your_amap_api_key
OPENAI_API_KEY=your_openai_api_key
WEATHER_API_KEY=your_weather_api_key

# JWTé…ç½®
JWT_SECRET=your_jwt_secret_key
JWT_EXPIRES_IN=7d

# æ–‡ä»¶å­˜å‚¨
UPLOAD_PATH=/var/www/uploads
MAX_FILE_SIZE=10485760

# æ—¥å¿—é…ç½®
LOG_LEVEL=info
LOG_PATH=/var/log/travel-agent

# ç›‘æ§é…ç½®
SENTRY_DSN=your_sentry_dsn
```

#### é…ç½®æ–‡ä»¶
```javascript
// config/database.js
module.exports = {
  mongodb: {
    uri: process.env.MONGODB_URI,
    options: {
      useNewUrlParser: true,
      useUnifiedTopology: true,
      maxPoolSize: 10,
      serverSelectionTimeoutMS: 5000,
      socketTimeoutMS: 45000,
    }
  },
  redis: {
    url: process.env.REDIS_URL,
    options: {
      retryDelayOnFailover: 100,
      enableReadyCheck: false,
      maxRetriesPerRequest: 3,
    }
  }
};

// config/app.js
module.exports = {
  port: process.env.PORT || 3000,
  env: process.env.NODE_ENV || 'development',
  cors: {
    origin: process.env.CORS_ORIGIN || '*',
    credentials: true
  },
  rateLimit: {
    windowMs: 15 * 60 * 1000, // 15åˆ†é’Ÿ
    max: 100 // é™åˆ¶æ¯ä¸ªIP 15åˆ†é’Ÿå†…æœ€å¤š100ä¸ªè¯·æ±‚
  }
};
```

### 3. Dockeréƒ¨ç½²

#### Dockerfileé…ç½®
```dockerfile
# å‰ç«¯Dockerfile
FROM node:18-alpine as builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]

# åç«¯Dockerfile
FROM node:18-alpine

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY package*.json ./
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# æ›´æ”¹æ–‡ä»¶æ‰€æœ‰æƒ
RUN chown -R nodejs:nodejs /app
USER nodejs

EXPOSE 3000
CMD ["npm", "start"]
```

#### Docker Composeé…ç½®
```yaml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - travel-agent-network
    restart: unless-stopped

  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - MONGODB_URI=mongodb://mongo:27017/travel_agent
      - REDIS_URL=redis://redis:6379
    depends_on:
      - mongo
      - redis
    networks:
      - travel-agent-network
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads

  # MongoDBæ•°æ®åº“
  mongo:
    image: mongo:5.0
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password
      - MONGO_INITDB_DATABASE=travel_agent
    volumes:
      - mongo_data:/data/db
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - travel-agent-network
    restart: unless-stopped

  # Redisç¼“å­˜
  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - travel-agent-network
    restart: unless-stopped

  # Nginxè´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - travel-agent-network
    restart: unless-stopped

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - travel-agent-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - travel-agent-network
    restart: unless-stopped

volumes:
  mongo_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  travel-agent-network:
    driver: bridge
```

### 4. Nginxé…ç½®

#### ä¸»é…ç½®æ–‡ä»¶
```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # åŸºç¡€é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend {
        least_conn;
        server backend:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    upstream frontend {
        server frontend:80;
    }

    # HTTPæœåŠ¡å™¨
    server {
        listen 80;
        server_name localhost;
        return 301 https://$server_name$request_uri;
    }

    # HTTPSæœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name localhost;

        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # å®‰å…¨å¤´
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

        # å‰ç«¯é™æ€æ–‡ä»¶
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # APIä»£ç†
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }

        # WebSocketæ”¯æŒ
        location /ws/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # é™æ€èµ„æºç¼“å­˜
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            proxy_pass http://frontend;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

### 5. éƒ¨ç½²è„šæœ¬

#### è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    log_info "æ£€æŸ¥ç³»ç»Ÿä¾èµ–..."
    
    if ! command -v docker &> /dev/null; then
        log_error "Dockeræœªå®‰è£…"
        exit 1
    fi
    
    if ! command -v docker-compose &> /dev/null; then
        log_error "Docker Composeæœªå®‰è£…"
        exit 1
    fi
    
    log_info "ä¾èµ–æ£€æŸ¥å®Œæˆ"
}

# ç¯å¢ƒæ£€æŸ¥
check_environment() {
    log_info "æ£€æŸ¥ç¯å¢ƒé…ç½®..."
    
    if [ ! -f .env ]; then
        log_error ".envæ–‡ä»¶ä¸å­˜åœ¨"
        exit 1
    fi
    
    if [ ! -f docker-compose.yml ]; then
        log_error "docker-compose.ymlæ–‡ä»¶ä¸å­˜åœ¨"
        exit 1
    fi
    
    log_info "ç¯å¢ƒæ£€æŸ¥å®Œæˆ"
}

# å¤‡ä»½æ•°æ®
backup_data() {
    log_info "å¤‡ä»½ç°æœ‰æ•°æ®..."
    
    if [ -d "data" ]; then
        timestamp=$(date +%Y%m%d_%H%M%S)
        tar -czf "backup_${timestamp}.tar.gz" data/
        log_info "æ•°æ®å¤‡ä»½å®Œæˆ: backup_${timestamp}.tar.gz"
    fi
}

# åœæ­¢æœåŠ¡
stop_services() {
    log_info "åœæ­¢ç°æœ‰æœåŠ¡..."
    docker-compose down --remove-orphans
    log_info "æœåŠ¡åœæ­¢å®Œæˆ"
}

# æ„å»ºé•œåƒ
build_images() {
    log_info "æ„å»ºDockeré•œåƒ..."
    docker-compose build --no-cache
    log_info "é•œåƒæ„å»ºå®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
start_services() {
    log_info "å¯åŠ¨æœåŠ¡..."
    docker-compose up -d
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 30
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if docker-compose ps | grep -q "Up"; then
        log_info "æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        log_error "æœåŠ¡å¯åŠ¨å¤±è´¥"
        docker-compose logs
        exit 1
    fi
}

# å¥åº·æ£€æŸ¥
health_check() {
    log_info "æ‰§è¡Œå¥åº·æ£€æŸ¥..."
    
    # æ£€æŸ¥APIæœåŠ¡
    if curl -f http://localhost/api/health > /dev/null 2>&1; then
        log_info "APIæœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        log_error "APIæœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi
    
    # æ£€æŸ¥å‰ç«¯æœåŠ¡
    if curl -f http://localhost > /dev/null 2>&1; then
        log_info "å‰ç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        log_error "å‰ç«¯æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi
    
    log_info "å¥åº·æ£€æŸ¥å®Œæˆ"
}

# æ¸…ç†æ—§é•œåƒ
cleanup_images() {
    log_info "æ¸…ç†æ—§é•œåƒ..."
    docker image prune -f
    log_info "é•œåƒæ¸…ç†å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    log_info "å¼€å§‹éƒ¨ç½²æ—…æ¸¸Agentç³»ç»Ÿ..."
    
    check_dependencies
    check_environment
    backup_data
    stop_services
    build_images
    start_services
    health_check
    cleanup_images
    
    log_info "éƒ¨ç½²å®Œæˆï¼"
    log_info "è®¿é—®åœ°å€: http://localhost"
    log_info "APIåœ°å€: http://localhost/api"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

#### PM2éƒ¨ç½²è„šæœ¬
```javascript
// ecosystem.config.js
module.exports = {
  apps: [
    {
      name: 'travel-agent-backend',
      script: './backend/dist/index.js',
      instances: 'max',
      exec_mode: 'cluster',
      env: {
        NODE_ENV: 'production',
        PORT: 3000
      },
      env_production: {
        NODE_ENV: 'production',
        PORT: 3000
      },
      error_file: './logs/err.log',
      out_file: './logs/out.log',
      log_file: './logs/combined.log',
      time: true,
      max_memory_restart: '1G',
      node_args: '--max-old-space-size=1024',
      watch: false,
      ignore_watch: ['node_modules', 'logs'],
      merge_logs: true,
      log_date_format: 'YYYY-MM-DD HH:mm:ss Z'
    }
  ],

  deploy: {
    production: {
      user: 'deploy',
      host: 'your-server-ip',
      ref: 'origin/main',
      repo: 'git@github.com:your-username/travel-agent.git',
      path: '/var/www/travel-agent',
      'pre-deploy-local': '',
      'post-deploy': 'npm install && npm run build && pm2 reload ecosystem.config.js --env production',
      'pre-setup': ''
    }
  }
};
```

## ğŸ”§ è¿ç»´ç®¡ç†

### 1. ç›‘æ§é…ç½®

#### Prometheusé…ç½®
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'travel-agent-backend'
    static_configs:
      - targets: ['backend:3000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'travel-agent-frontend'
    static_configs:
      - targets: ['frontend:80']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'mongodb'
    static_configs:
      - targets: ['mongo:27017']
    scrape_interval: 10s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 10s
```

#### Grafanaä»ªè¡¨æ¿
```json
{
  "dashboard": {
    "title": "æ—…æ¸¸Agentç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "APIå“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])",
            "legendFormat": "{{method}} {{route}}"
          }
        ]
      },
      {
        "title": "è¯·æ±‚é€Ÿç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{route}}"
          }
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xxé”™è¯¯"
          }
        ]
      }
    ]
  }
}
```

### 2. æ—¥å¿—ç®¡ç†

#### æ—¥å¿—é…ç½®
```javascript
// config/logger.js
const winston = require('winston');
const DailyRotateFile = require('winston-daily-rotate-file');

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'travel-agent' },
  transports: [
    // é”™è¯¯æ—¥å¿—
    new DailyRotateFile({
      filename: 'logs/error-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      level: 'error',
      maxSize: '20m',
      maxFiles: '14d'
    }),
    
    // æ‰€æœ‰æ—¥å¿—
    new DailyRotateFile({
      filename: 'logs/combined-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '14d'
    })
  ]
});

// å¼€å‘ç¯å¢ƒè¾“å‡ºåˆ°æ§åˆ¶å°
if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.simple()
  }));
}

module.exports = logger;
```

### 3. å¤‡ä»½ç­–ç•¥

#### æ•°æ®åº“å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# scripts/backup.sh

# é…ç½®
BACKUP_DIR="/var/backups/travel-agent"
MONGODB_URI="mongodb://localhost:27017/travel_agent"
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/mongodb_backup_$TIMESTAMP.gz"

# MongoDBå¤‡ä»½
echo "å¼€å§‹MongoDBå¤‡ä»½..."
mongodump --uri="$MONGODB_URI" --archive="$BACKUP_FILE" --gzip

if [ $? -eq 0 ]; then
    echo "MongoDBå¤‡ä»½æˆåŠŸ: $BACKUP_FILE"
else
    echo "MongoDBå¤‡ä»½å¤±è´¥"
    exit 1
fi

# æ¸…ç†æ—§å¤‡ä»½
find $BACKUP_DIR -name "mongodb_backup_*.gz" -mtime +$RETENTION_DAYS -delete

echo "å¤‡ä»½å®Œæˆ"
```

#### è‡ªåŠ¨å¤‡ä»½å®šæ—¶ä»»åŠ¡
```bash
# æ·»åŠ åˆ°crontab
# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /var/www/travel-agent/scripts/backup.sh >> /var/log/backup.log 2>&1
```

### 4. å®‰å…¨é…ç½®

#### é˜²ç«å¢™é…ç½®
```bash
# UFWé˜²ç«å¢™é…ç½®
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å…è®¸SSH
sudo ufw allow ssh

# å…è®¸HTTP/HTTPS
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp

# å…è®¸åº”ç”¨ç«¯å£
sudo ufw allow 3000/tcp

# å¯ç”¨é˜²ç«å¢™
sudo ufw enable
```

#### SSLè¯ä¹¦é…ç½®
```bash
# ä½¿ç”¨Let's Encryptè·å–SSLè¯ä¹¦
sudo apt-get install certbot python3-certbot-nginx

# è·å–è¯ä¹¦
sudo certbot --nginx -d your-domain.com

# è‡ªåŠ¨ç»­æœŸ
sudo crontab -e
# æ·»åŠ ä»¥ä¸‹è¡Œ
0 12 * * * /usr/bin/certbot renew --quiet
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. åº”ç”¨æ€§èƒ½ä¼˜åŒ–

#### Node.jsä¼˜åŒ–
```javascript
// é›†ç¾¤æ¨¡å¼å¯åŠ¨
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`ä¸»è¿›ç¨‹ ${process.pid} æ­£åœ¨è¿è¡Œ`);

  // åˆ›å»ºå·¥ä½œè¿›ç¨‹
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`å·¥ä½œè¿›ç¨‹ ${worker.process.pid} å·²é€€å‡º`);
    cluster.fork(); // é‡å¯å·¥ä½œè¿›ç¨‹
  });
} else {
  require('./app');
  console.log(`å·¥ä½œè¿›ç¨‹ ${process.pid} å·²å¯åŠ¨`);
}
```

#### æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
```javascript
// æ•°æ®åº“è¿æ¥æ± é…ç½®
const mongoose = require('mongoose');

mongoose.connect(process.env.MONGODB_URI, {
  maxPoolSize: 10,
  minPoolSize: 2,
  maxIdleTimeMS: 30000,
  serverSelectionTimeoutMS: 5000,
  socketTimeoutMS: 45000,
  bufferMaxEntries: 0,
  bufferCommands: false
});
```

### 2. ç¼“å­˜ä¼˜åŒ–

#### Redisè¿æ¥æ± 
```javascript
const Redis = require('ioredis');

const redis = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379,
  password: process.env.REDIS_PASSWORD,
  db: 0,
  retryDelayOnFailover: 100,
  enableReadyCheck: false,
  maxRetriesPerRequest: 3,
  lazyConnect: true,
  keepAlive: 30000,
  family: 4,
  maxLoadingTimeout: 10000
});
```

## ğŸ”„ æŒç»­éƒ¨ç½²

### 1. CI/CDé…ç½®

#### GitHub Actionsé…ç½®
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup Node.js
      uses: actions/setup-node@v2
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: |
        npm ci
        cd backend && npm ci
        
    - name: Run tests
      run: |
        npm test
        cd backend && npm test
        
    - name: Build
      run: |
        npm run build
        cd backend && npm run build

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to server
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.HOST }}
        username: ${{ secrets.USERNAME }}
        key: ${{ secrets.KEY }}
        script: |
          cd /var/www/travel-agent
          git pull origin main
          docker-compose down
          docker-compose build --no-cache
          docker-compose up -d
          docker system prune -f
```

### 2. å›æ»šç­–ç•¥

#### å›æ»šè„šæœ¬
```bash
#!/bin/bash
# scripts/rollback.sh

set -e

# è·å–å½“å‰ç‰ˆæœ¬
CURRENT_VERSION=$(git rev-parse HEAD)
PREVIOUS_VERSION=$(git rev-parse HEAD~1)

echo "å½“å‰ç‰ˆæœ¬: $CURRENT_VERSION"
echo "å›æ»šåˆ°ç‰ˆæœ¬: $PREVIOUS_VERSION"

# åœæ­¢æœåŠ¡
docker-compose down

# å›æ»šä»£ç 
git reset --hard $PREVIOUS_VERSION

# é‡æ–°æ„å»ºå’Œå¯åŠ¨
docker-compose build --no-cache
docker-compose up -d

echo "å›æ»šå®Œæˆ"
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2024å¹´12æœˆ  
**ç»´æŠ¤è€…**: è¿ç»´å›¢é˜Ÿ 